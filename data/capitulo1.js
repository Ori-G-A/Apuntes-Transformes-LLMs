// data/capitulo1.js
const capitulo1 = {
    id: "1",
    title: "Cap√≠tulo 1: Fundamentos",
    parts: [
        {
            id: "1.1",
            title: "1.1 Neural Networks",
            subsections: [
                {
                    subid: "1.1.1",
                    subtitle: "Overview",
                    description: "Introducci√≥n a los conceptos fundamentales de las redes neuronales y su arquitectura b√°sica.",
                    concepts: [ {
                    acronym: "NN",
                    name: "Neural Network",
                    definition: "Modelo inspirado en el cerebro y es la unidad b√°sica de aprendizaje profundo. Se compone de neuronas interconectadas que procesan informaci√≥n mediante pesos ajustables, permitiendo que la m√°quina aprenda patrones complejos que no son lineales."
                },
                {
                    acronym: "FFNN",
                    name: "Feed-Forward Neural Network",
                    definition: "La arquitectura m√°s simple donde la informaci√≥n viaja en una sola direcci√≥n: desde la entrada (Input), pasando por capas ocultas (Hidden) que extraen caracter√≠sticas, hasta la salida (Output) que da la predicci√≥n final.\n\nüîé A mayor n√∫mero de capas ocultas, m√°s profunda es la red. Redes con pocas capas (k ‚â§ 3) se consideran shallow networks."
                }
                ]
                },
                {
                    subid: "1.1.2",
                    subtitle: "Components",
                    description: "Componentes detallados de las redes neuronales: entrada, capas ocultas, funciones de activaci√≥n y salida.",
                    concepts: [ {
                    acronym: "Input",
                    name: "Input Layer",
                    definition: "Vector de embedding i ‚àà ‚Ñù·µê. Puede representar texto (embeddings), audio (espectrogramas) o im√°genes (p√≠xeles). \n\nüí° Idea clave: independientemente de la modalidad, todo se traduce a vectores num√©ricos."
                },
                {
                    acronym: "Hidden",
                    name: "Hidden Layer",
                    definition: "Capa que transforma la entrada usando pesos (W), sesgos (b) y activaciones (A) para aprender patrones. Formalmente: z = W¬∑x + b con output = A(z).\n El c√°lculo se implementa eficientemente mediante multiplicaciones matriciales."
                },
                {
                    acronym: "Output",
                    name: "Output Layer",
                    definition: "Devuelve la predicci√≥n final o ‚àà ‚Ñù‚Åø.\n Permiten un flujo de informaci√≥n m√°s controlado y mejoran el rendimiento en modelos grandes"
                },
                {
                    acronym: "Sigmoid",
                    name: "Sigmoid Function",
                    definition: "œÉ(z) = 1/(1+e‚Åª·∂ª). Transforma cualquier valor a un rango entre 0 y 1. Es ideal para predicciones de probabilidad, aunque sufre del problema de \"gradiente desvaneciente\".",
                },
                {
                    acronym: "ReLU",
                    name: "Rectified Linear Unit",
                    definition: "max(0,z). Rango [0,+‚àû). Es la m√°s usada hoy en d√≠a. Si el valor es negativo, lo vuelve 0; si es positivo, lo deja igual. \n\n‚ö†Ô∏è Nota t√©cnica: Es computacionalmente muy eficiente, aunque no es diferenciable en 0."
                },
                {
                    acronym: "Leaky ReLU",
                    name: "Leaky Rectified Linear Unit",
                    definition: "Variante de ReLU definida como max(Œµz, z) con Œµ ‚â™ 1 (t√≠picamente 0.01). Soluciona el problema de neuronas muertas permitiendo un peque√±o gradiente negativo cuando z < 0. Mantiene los beneficios de ReLU mientras previene la muerte neuronal."
                },
                {
                    acronym: "GELU",
                    name: "Gaussian Error Linear Unit",
                    fullName: "Unidad Lineal de Error Gaussiano",
                    definition: "Funci√≥n de activaci√≥n z¬∑P(X ‚â§ z) donde X ~ N(0,1). Proporciona una transici√≥n m√°s suave que ReLU. Es la activaci√≥n est√°ndar en transformers modernos (BERT, GPT-3, GPT-4) por su mejor rendimiento emp√≠rico. Rango de salida: aproximadamente (-0.17, +‚àû)."
                },
                {
                    acronym: "ELU",
                    name: "Exponential Linear Unit",
                    fullName: "Unidad Lineal Exponencial",
                    definition: "Funci√≥n max(Œ±(e^z - 1), z) con Œ± ‚âà 1. Combina beneficios de ReLU con outputs negativos suaves. Ayuda a que las activaciones est√©n centradas en cero. Computacionalmente m√°s costosa que ReLU pero puede converger m√°s r√°pido."
                },
                {
                    acronym: "GLU",
                    name: "Gated Linear Unit",
                    fullName: "Unidad Lineal con Compuerta",
                    definition: "Funci√≥n de activaci√≥n con mecanismo de compuerta: A(z) = A‚ÇÅ(z) ‚äô A‚ÇÇ(z), donde ‚äô es multiplicaci√≥n elemento a elemento. GLU usa œÉ(zW+b) como compuerta. Permite al modelo aprender qu√© informaci√≥n dejar pasar din√°micamente."
                },
                {
                    acronym: "SwiGLU",
                    name: "Swish Gated Linear Unit",
                    fullName: "Unidad Lineal con Compuerta Swish",
                    definition: "Variante de GLU que usa (zW+b) ‚äô œÉ(Œ≤(zW+b)) donde Œ≤ es aprendible. Combina la suavidad de Swish con el control de gating. Muy efectiva en transformers grandes. Usada en modelos como PaLM y LLaMA."
                },
                {
                    acronym: "ReGLU",
                    name: "Rectified Gated Linear Unit",
                    fullName: "Unidad Lineal con Compuerta Rectificada",
                    definition: "Variante de GLU usando ReLU(zW+b) como funci√≥n de gating. Mantiene la simplicidad de ReLU con el poder expresivo del gating. Usada en algunos modelos de lenguaje por su balance entre eficiencia y rendimiento."
                },
                {
                    acronym: "Softmax",
                    name: "Softmax Function",
                    definition: "Convierte el vector de salida en una distribuci√≥n de probabilidad donde la suma es 1. Usada en clasificaci√≥n."
                }
            ]
                }
            ]
        },
        {
            id: "1.2",
            title: "1.2 Training",
            description: "Procesos, algoritmos y t√©cnicas para el aprendizaje de par√°metros.",
            subsections: [ // <--- IMPORTANTE: Todo debe ir dentro de este array
                {
                    subid: "1.2.1",
                    subtitle: "Parameter Learning",
                    description: "Introducci√≥n a los conceptos fundamentales...",
                    concepts: [ 
                    {
                        acronym: "Xavier/Glorot",
                        name: "Xavier Initialization",
                        fullName: "Inicializaci√≥n Xavier/Glorot",
                        definition: "M√©todo de inicializaci√≥n de pesos para activaciones Sigmoid/Tanh. Uniforme: U[-‚àö(6/(n·µ¢+n‚Çí)), ‚àö(6/(n·µ¢+n‚Çí))]. Normal: N(0, ‚àö(2/(n·µ¢+n‚Çí))). Mantiene la varianza de activaciones y gradientes similar entre capas, evitando desvanecimiento/explosi√≥n. n·µ¢ = neuronas entrada, n‚Çí = neuronas salida."
                    },
                    {
                        acronym: "He Init",
                        name: "He Initialization",
                        fullName: "Inicializaci√≥n He",
                        definition: "M√©todo de inicializaci√≥n √≥ptimo para ReLU y derivados. Uniforme: U[-‚àö(6/n·µ¢), ‚àö(6/n·µ¢)]. Normal: N(0, ‚àö(2/n·µ¢)). Dise√±ado espec√≠ficamente para funciones de activaci√≥n que tienen z=0 como punto de inflexi√≥n. Esencial para redes profundas con ReLU."
                    },
                    {
                        acronym: "Epoch",
                        name: "Training Epoch",
                        fullName: "√âpoca de Entrenamiento",
                        definition: "Una iteraci√≥n completa donde el modelo ve todo el conjunto de entrenamiento una vez. Relacionados: N (tama√±o entrenamiento), b (batch size), s (steps por √©poca). F√≥rmula: N = b √ó s. El entrenamiento t√≠picamente requiere m√∫ltiples √©pocas (10-1000+) para convergencia."
                    },
                    {
                        acronym: "Batch Size",
                        name: "Batch Size",
                        fullName: "Tama√±o de Lote",
                        definition: "N√∫mero de observaciones procesadas simult√°neamente en cada paso. Mini-batch t√≠pico: 32, 64, 128, 256 (potencias de 2 para optimizaci√≥n hardware). Batch grande: gradiente m√°s estable pero m√°s memoria. Batch peque√±o: m√°s ruidoso pero mejor generalizaci√≥n. Trade-off clave en entrenamiento."
                    },
                    {
                        acronym: "Loss",
                        name: "Loss Function",
                        fullName: "Funci√≥n de P√©rdida",
                        definition: "Funci√≥n L(≈∑, y) que cuantifica la diferencia entre predicciones ≈∑ y valores reales y. Valores m√°s altos = peor rendimiento. El objetivo del entrenamiento es minimizar L. Escrita como L(Œ∏) para indicar dependencia de par√°metros del modelo."
                    },
                    {
                        acronym: "Hard Label",
                        name: "Hard Label",
                        fullName: "Etiqueta Dura",
                        definition: "Etiqueta binaria donde cada observaci√≥n pertenece (y·µ¢=1) o no (y·µ¢=0) a clase i. Usada en clasificaci√≥n de im√°genes tradicional. Ejemplo: una imagen es 100% 'gato' o 100% 'perro', sin ambig√ºedad. No captura incertidumbre."
                    },
                    {
                        acronym: "Soft Label",
                        name: "Soft Label",
                        fullName: "Etiqueta Suave",
                        definition: "Etiqueta probabil√≠stica donde y·µ¢ ‚àà [0,1] indica la probabilidad de pertenecer a clase i. Com√∫n en NLP para predicci√≥n de siguiente palabra donde m√∫ltiples completaciones son v√°lidas. Ejemplo: 'El oso es...' ‚Üí 50% 'grande', 30% 'peludo', 20% 'salvaje'. Captura incertidumbre."
                    },
                    {
                        acronym: "Backprop",
                        name: "Backpropagation",
                        fullName: "Retropropagaci√≥n",
                        definition: "Algoritmo fundamental para entrenar redes neuronales. Calcula gradientes ‚àáL(Œ∏) mediante regla de la cadena desde la salida hacia la entrada. Tres pasos: (1) Forward pass: calcular ≈∑ y L, (2) Backward pass: calcular ‚àÇL/‚àÇŒ∏·µ¢ para cada par√°metro, (3) Update: ajustar Œ∏·µ¢ en direcci√≥n que reduce L."
                    },
                    {
                        acronym: "Grad Clip",
                        name: "Gradient Clipping",
                        fullName: "Recorte de Gradiente",
                        definition: "T√©cnica para prevenir explosi√≥n de gradientes. Limita la norma del gradiente ||‚àáL|| a un valor m√°ximo C. Si ||‚àáL|| > C, se escala a C. Previene actualizaciones de pesos de magnitud no deseada. Esencial en RNNs y transformers. T√≠picamente C ‚àà [1, 5]."
                    },
                    {
                        acronym: "LR / Œ± / Œ∑",
                        name: "Learning Rate",
                        fullName: "Tasa de Aprendizaje",
                        definition: "Hiperpar√°metro que controla la magnitud de actualizaci√≥n de pesos. Muy bajo: convergencia lenta, puede quedar atrapado en m√≠nimos locales. Ideal: converge eficientemente al √≥ptimo. Muy alto: puede divergir o saltar sobre el √≥ptimo. Puede ser fijo o seguir un schedule (decay, warmup, etc.)."
                    },
                    {
                        acronym: "Warmup",
                        name: "Learning Rate Warmup",
                        fullName: "Calentamiento de Tasa de Aprendizaje",
                        definition: "T√©cnica que usa LR bajo durante los primeros s‚Çó·µ• steps (warmup steps) para prevenir overfitting temprano. El LR aumenta gradualmente hasta alcanzar el valor objetivo. F√≥rmula t√≠pica: Œ±(s) = C¬∑min(1/‚àös, s/s‚Çó·µ•^(3/2)). Cr√≠tico en transformers grandes. Previene cambios dram√°ticos por gradientes ruidosos iniciales."
                    }
                ]
                },
                {
                    subid: "1.2.2",
                    subtitle: "Optimizers",
                    description: "Algoritmos que actualizan los par√°metros del modelo para minimizar la p√©rdida. Cada uno tiene diferentes estrategias para calcular y aplicar las actualizaciones bas√°ndose en los gradientes.",
                    concepts: [
                    {
                        acronym: "GD",
                        name: "Gradient Descent",
                        definition: "Optimizador b√°sico que actualiza par√°metros en direcci√≥n del mayor descenso: Œ∏‚Çú‚Çä‚ÇÅ = Œ∏‚Çú - Œ±‚àáL(Œ∏‚Çú). Tres variantes: (1) Stochastic: usa 1 observaci√≥n (r√°pido, ruidoso), (2) Mini-batch: usa subconjunto (balance √≥ptimo), (3) Batch: usa todo el dataset (estable, costoso). Mini-batch es el est√°ndar."
                    },
                    {
                        acronym: "SGD",
                        name: "Stochastic Gradient Descent",
                        definition: "Variante de GD que calcula p√©rdida y gradiente usando una sola observaci√≥n por iteraci√≥n. Ventajas: bajo consumo de memoria, muchas actualizaciones por √©poca. Desventajas: gradiente muy ruidoso, convergencia err√°tica. En pr√°ctica, 'SGD' suele referirse a mini-batch GD."
                    },
                    {
                        acronym: "Momentum",
                        name: "Momentum Optimizer",
                        definition: "Optimizador que acelera convergencia considerando gradientes previos. Actualizaci√≥n: v‚Çú‚Çä‚ÇÅ = Œ≤v‚Çú + (1-Œ≤)‚àáL(Œ∏‚Çú), luego Œ∏‚Çú‚Çä‚ÇÅ = Œ∏‚Çú - Œ±v‚Çú. Œ≤ t√≠picamente 0.9. Reduce oscilaciones, ayuda a escapar m√≠nimos locales. Como una bola rodando que acumula inercia. Suaviza la trayectoria de optimizaci√≥n."
                    },
                    {
                        acronym: "RMSProp",
                        name: "Root Mean Square Propagation",
                        definition: "Optimizador con tasas de aprendizaje adaptativas. Mantiene promedio m√≥vil de gradientes al cuadrado: v‚Çú‚Çä‚ÇÅ = Œ≤v‚Çú + (1-Œ≤)(‚àáL(Œ∏‚Çú))¬≤. Actualiza: Œ∏‚Çú‚Çä‚ÇÅ = Œ∏‚Çú - Œ±¬∑‚àáL(Œ∏‚Çú)/‚àö(v‚Çú+Œµ). Œ± t√≠picamente 0.001, Œ≤ = 0.9. Normaliza gradientes, previene desvanecimiento/explosi√≥n. Par√°metros con gradientes grandes tienen LR efectivo menor."
                    },
                    {
                        acronym: "Adam",
                        name: "Adaptive Moment Estimation",
                        definition: "Optimizador m√°s popular que combina Momentum + RMSProp. Mantiene dos promedios m√≥viles: m‚Çú (primer momento, gradiente), v‚Çú (segundo momento, gradiente¬≤). Actualizaci√≥n: Œ∏‚Çú‚Çä‚ÇÅ = Œ∏‚Çú - Œ±¬∑m‚Çú/‚àö(v‚Çú+Œµ). Hiperpar√°metros: Œ±=0.001, Œ≤‚ÇÅ=0.9, Œ≤‚ÇÇ=0.999. Tasas de aprendizaje adaptativas + momentum. Est√°ndar en deep learning."
                    },
                    {
                        acronym: "AdamW",
                        name: "Adam with Weight Decay",
                        definition: "Variante de Adam que separa weight decay de la regularizaci√≥n L2. Elimina el t√©rmino L2 del gradiente y lo incorpora directamente en la actualizaci√≥n de pesos. Mejora convergencia y generalizaci√≥n. Est√°ndar en entrenamiento de transformers (BERT, GPT). Previene interferencia entre regularizaci√≥n y tasas adaptativas."
                    },
                    {
                        acronym: "Adafactor",
                        name: "Adafactor Optimizer",
                        definition: "Extensi√≥n de Adam que reduce requisitos de memoria mediante aproximaci√≥n de bajo rango de gradientes al cuadrado. En lugar de guardar matriz completa de segundos momentos, usa factorizaci√≥n. Cr√≠tico para entrenar modelos enormes (ej: T5, PaLM). Trade-off: menos memoria por aproximaci√≥n potencialmente menos precisa."
                    }
                ]
                },
                {
                    subid: "1.2.3",
                    subtitle: "Common Loss Functions",
                    description: "Las funciones de p√©rdida cuantifican qu√© tan lejos est√°n las predicciones del modelo de los valores reales.",
                    concepts: [ 
                    {
                        acronym: "CE",
                        name: "Cross-Entropy Loss",
                        definition: "Funci√≥n de p√©rdida est√°ndar para clasificaci√≥n. Mide divergencia entre distribuciones de probabilidad predicha y real. Multi-clase: CE(≈∑,y) = -Œ£·µ¢ y·µ¢¬∑log(≈∑·µ¢). Penaliza fuertemente predicciones confiadas pero incorrectas. Valores: [0, +‚àû), donde 0 = predicci√≥n perfecta. Usada con softmax en capa final."
                    },
                    {
                        acronym: "BCE",
                        name: "Binary Cross-Entropy",
                        definition: "Caso especial de CE para clasificaci√≥n binaria (y ‚àà {0,1}). F√≥rmula: BCE(≈∑,y) = -[y¬∑log(≈∑) + (1-y)¬∑log(1-≈∑)]. Cuando y=1, solo el primer t√©rmino importa. Cuando y=0, solo el segundo. Usada con sigmoid en salida. Cr√≠tica en detecci√≥n, clasificaci√≥n binaria."
                    },
                    {
                        acronym: "KL Div",
                        name: "Kullback-Leibler Divergence",
                        definition: "Medida de diferencia entre dos distribuciones de probabilidad P y Q. F√≥rmula: KL(P||Q) = Œ£·µ¢ p·µ¢¬∑log(p·µ¢/q·µ¢). NO es sim√©trica: KL(P||Q) ‚â† KL(Q||P). Valores: [0, +‚àû) donde 0 = distribuciones id√©nticas. Aplicaciones: NLP, compresi√≥n, VAEs, t-SNE, destilaci√≥n de conocimiento."
                    },
                    {
                        acronym: "MAE",
                        name: "Mean Absolute Error",
                        definition: "Funci√≥n de p√©rdida L1 para regresi√≥n. F√≥rmula: MAE = (1/n)¬∑Œ£·µ¢|≈∑·µ¢-y·µ¢|. Menos sensible a outliers que MSE (contribuci√≥n lineal vs cuadr√°tica). Buena elecci√≥n cuando outliers no deben dominar la p√©rdida. Gradiente constante. No diferenciable en 0. Interpretaci√≥n: error promedio en unidades originales."
                    },
                    {
                        acronym: "MSE",
                        name: "Mean Squared Error",
                        definition: "Funci√≥n de p√©rdida L2 para regresi√≥n. F√≥rmula: MSE = (1/n)¬∑Œ£·µ¢(≈∑·µ¢-y·µ¢)¬≤. M√ÅS sensible a outliers (errores grandes contribuyen cuadr√°ticamente). Diferenciable en todos lados. Penaliza errores grandes desproporcionadamente. Usada en regresi√≥n est√°ndar. Unidades: cuadrado de la variable objetivo."
                    },
                    {
                        acronym: "RMSE",
                        name: "Root Mean Squared Error",
                        definition: "RMSE = ‚àöMSE. Ventaja sobre MSE: mismas unidades que variable objetivo, m√°s interpretable. Mantiene sensibilidad a outliers de MSE. Com√∫n en benchmarks y reportes. Ejemplo: si predices precios en $, RMSE tambi√©n est√° en $, mientras MSE estar√≠a en $¬≤."
                    }   
                    
                ]
                },
                {
                    subid: "1.2.2",
                    subtitle: "Regularization",
                    description: "T√©cnicas de regularizaci√≥n previenen el overfitting forzando al modelo a aprender patrones generales en lugar de memorizar el conjunto de entrenamiento.",
                    concepts: [ 
                    {
                        acronym: "Dropout",
                        name: "Dropout Regularization",
                        fullName: "Regularizaci√≥n por Dropout",
                        definition: "T√©cnica que aleatoriamente 'apaga' neuronas con probabilidad p durante entrenamiento. Training: cada neurona se dropea con prob p, forzando redundancia. Inference: ninguna se dropea, pero activaciones se escalan por (1-p) para compensar. Previene co-adaptaci√≥n de neuronas. p t√≠picamente 0.5 para capas ocultas, 0.1-0.2 para entrada."
                    },
                    {
                        acronym: "L1 Reg",
                        name: "L1 Regularization / LASSO",
                        fullName: "Regularizaci√≥n L1 / LASSO",
                        definition: "Penaliza suma de valores absolutos de pesos: L + Œª||Œ∏||‚ÇÅ con Œª>0. Produce sparsity: muchos pesos se vuelven exactamente 0. Excelente para feature selection autom√°tica. Contorno: forma de diamante. Trade-off: Œª grande = m√°s sparsity pero posible underfitting. √ötil cuando muchos features son irrelevantes."
                    },
                    {
                        acronym: "L2 Reg",
                        name: "L2 Regularization / Ridge",
                        fullName: "Regularizaci√≥n L2 / Ridge",
                        definition: "Penaliza suma de cuadrados de pesos: L + Œª||Œ∏||‚ÇÇ¬≤ con Œª>0. Reduce magnitud de coeficientes pero raramente los hace 0. Contorno: forma circular. Prefiere soluciones con pesos peque√±os y distribuidos. Equivalente a prior Gaussiano en perspectiva Bayesiana. M√°s com√∫n que L1 en deep learning."
                    },
                    {
                        acronym: "Elastic Net",
                        name: "Elastic Net Regularization",
                        fullName: "Regularizaci√≥n Elastic Net",
                        definition: "Combina L1 y L2: L + Œª[(1-Œ±)||Œ∏||‚ÇÅ + Œ±||Œ∏||‚ÇÇ¬≤] con Œª>0, Œ±‚àà[0,1]. Œ±=0: puro L1 (sparsity). Œ±=1: puro L2 (shrinkage). Œ± intermedio: balance entre feature selection y coeficientes peque√±os. √ötil cuando hay grupos de features correlacionados."
                    },
                    {
                        acronym: "Early Stop",
                        name: "Early Stopping",
                        fullName: "Parada Temprana",
                        definition: "Detiene entrenamiento cuando p√©rdida de validaci√≥n deja de mejorar o empieza a empeorar. Monitorea L·µ•‚Çê‚Çó cada √©poca. Si no mejora por n √©pocas (patience), detiene y restaura mejores pesos. Previene overfitting sin modificar arquitectura. Simple pero muy efectivo. Par√°metros t√≠picos: patience=5-20 √©pocas."
                    },
                    {
                        acronym: "BN",
                        name: "Batch Normalization",
                        definition: "Normaliza entradas a trav√©s de batch. Proceso: (1) Calcula Œº y œÉ¬≤ del batch, (2) Normaliza: xÃÇ=(x-Œº)/‚àö(œÉ¬≤+Œµ), (3) Escala/desplaza: BN(x)=Œ≥xÃÇ+Œ≤ donde Œ≥,Œ≤ aprendibles. Beneficios: estabiliza entrenamiento, permite LR mayores, reduce dependencia de inicializaci√≥n, act√∫a como regularizaci√≥n."
                    }
                ]
                }
            ]
        },
        {
            id: "1.3",
            title: "1.3 Evaluation",
            description: "M√©tricas y metodolog√≠as para medir el rendimiento del modelo.",
            subsections: [ // <--- IMPORTANTE: Todo debe ir dentro de este array
                {
                    subid: "1.3.1",
                    subtitle: "Data Splits",
                    description: "Divisi√≥n correcta de datos para entrenamiento, validaci√≥n y prueba.",
                    concepts: [
                    {
                        acronym: "Train Set",
                        name: "Training Set",
                        definition: "Datos para que modelo aprenda patrones: f(x‚Çú·µ£‚Çê·µ¢‚Çô)‚Üí≈∑, minimizando L(≈∑,y‚Çú·µ£‚Çê·µ¢‚Çô). Debe ser: (1) Grande para capturar patrones, (2) Representativo de poblaci√≥n, (3) Alta calidad (sin duplicados, con edge cases). T√≠picamente 60-80% del dataset. √önico conjunto donde modelo 've' etiquetas durante entrenamiento."
                    },
                    {
                        acronym: "Val Set",
                        name: "Validation Set",
                        definition: "Datos para tuning de hiperpar√°metros y selecci√≥n de modelo. Permite comparar arquitecturas, ajustar LR, determinar early stopping. Debe ser: (1) Proxy representativo, (2) Tama√±o balanceado, (3) Independiente de train. T√≠picamente 10-20%. Tambi√©n llamado dev set."
                    },
                    {
                        acronym: "Test Set",
                        name: "Test Set",
                        definition: "SOLO para reportar resultados finales. Mide generalizaci√≥n en datos no vistos. NUNCA para decisiones de entrenamiento/arquitectura. Pitfalls: (1) Contaminaci√≥n, (2) Feature leakage, (3) Distribution mismatch. T√≠picamente 10-20%."
                    },
                    {
                        acronym: "Cross-Val",
                        name: "Cross-Validation",
                        definition: "Divide datos en k folds, entrena k veces (cada vez con fold diferente para validaci√≥n). k-fold t√≠pico: k=5 o 10. Reduce dependencia de split espec√≠fico. Ventaja: usa mejor datos. Desventaja: k veces m√°s costoso. Poco pr√°ctico en DL por tiempo. Com√∫n en ML tradicional."
                    },
                    {
                        acronym: "Data Contam",
                        name: "Data Contamination",
                        definition: "Observaciones del test en train (duplicados, leakage). Causa m√©tricas infladas artificialmente. Modelo memoriza en lugar de generalizar. Verificar con hashing. En LLMs: problema cuando datos de eval filtraron en corpus de pretraining."
                    },
                    {
                        acronym: "Feature Leak",
                        name: "Feature Leakage",
                        definition: "Usar info del test durante training indirectamente. Ejemplo: normalizar todo dataset antes de split (constantes incluyen info test). Soluci√≥n: fit transformaciones SOLO en train, aplicar a val/test. Tambi√©n: usar features no disponibles en producci√≥n (info del futuro)."
                    }
                ]
                },
                {
                    subid: "1.3.2",
                    subtitle: "Metrics",
                    description: "M√©tricas para evaluar el rendimiento de modelos de clasificaci√≥n.",
                    concepts: [
                    {
                        acronym: "CM",
                        name: "Confusion Matrix",
                        definition: "Tabla 2√ó2 para clasificaci√≥n binaria: TP (predijo +, es +), TN (predijo -, es -), FP (predijo +, es -), FN (predijo -, es +). Visualiza tipos de errores. Extensible a multi-clase (matriz k√ók). Base para precision, recall, F1, accuracy."
                    },
                    {
                        acronym: "Accuracy",
                        name: "Accuracy",
                        definition: "Porcentaje correcto: (TN+TP)/(TN+FN+FP+TP). Simple e intuitiva. PROBLEMA: enga√±osa con clases desbalanceadas. Ejemplo: 95% negativos‚Üípredecir siempre negativo=95% accuracy pero in√∫til. Usar con precauci√≥n. Mejor combinar con precision/recall."
                    },
                    {
                        acronym: "Precision",
                        name: "Precision",
                        definition: "De predicciones positivas, cu√°ntas correctas: TP/(FP+TP). Pregunta: '¬øQu√© tan confiable cuando dice positivo?' Alta precision=pocos FP. Cr√≠tica cuando costo FP alto. Ejemplo: spam detection (marcar email leg√≠timo como spam es costoso). Trade-off con recall."
                    },
                    {
                        acronym: "Recall",
                        name: "Recall / Sensitivity",
                        definition: "De casos realmente positivos, cu√°ntos detecta: TP/(FN+TP). Pregunta: '¬øQu√© tan completa la detecci√≥n?' Alto recall=pocos FN. Cr√≠tico cuando costo FN alto. Ejemplo: detecci√≥n de c√°ncer (no detectar caso real es costoso). Trade-off con precision."
                    },
                    {
                        acronym: "F1",
                        name: "F1 Score",
                        definition: "Media arm√≥nica de precision y recall: F1=2TP/(FN+FP+2TP)=2¬∑(precision¬∑recall)/(precision+recall). Rango: [0,1], 1=perfecto. Solo alto cuando AMBAS altas. Ideal para clases desbalanceadas. Variantes: F2 (favorece recall), F0.5 (favorece precision)."
                    },
                    {
                        acronym: "TPR",
                        name: "True Positive Rate",
                        definition: "Equivalente a Recall: TP/(FN+TP). Tambi√©n 'power' o '1-FNR'. Proporci√≥n de positivos correctamente identificados. Eje Y en ROC. Pregunta: '¬øQu√© fracci√≥n de casos positivos capta?' Rango: [0,1], 1=detecta todos."
                    },
                    {
                        acronym: "FPR",
                        name: "False Positive Rate",
                        definition: "De negativos reales, cu√°ntos marca como positivos: FP/(TN+FP)=1-TNR. Tambi√©n 'Type I error'. Eje X en ROC. Pregunta: '¬øQu√© fracci√≥n de negativos incorrectamente marcados?' Rango: [0,1], 0=no produce FP."
                    },
                    {
                        acronym: "TNR",
                        name: "True Negative Rate",
                        definition: "Especificidad: TN/(TN+FP)=1-FPR. Proporci√≥n de negativos correctamente identificados. Importante cuando identificar negativos correctamente es cr√≠tico. Ejemplo: screening m√©dico, evitar alarmas falsas."
                    },
                    {
                        acronym: "FNR",
                        name: "False Negative Rate",
                        definition: "Type II error: FN/(FN+TP)=1-TPR. De positivos reales, cu√°ntos no detecta. Cr√≠tico en aplicaciones seguridad/salud donde fallar en detectar positivo tiene consecuencias graves. Ejemplo: no detectar fraude, no detectar enfermedad."
                    },
                    {
                        acronym: "ROC",
                        name: "ROC Curve",
                        definition: "Grafica TPR vs FPR para todos umbrales posibles. Eje X: FPR, Eje Y: TPR. Cada punto=un umbral. Umbral bajo: todos predichos +, (FPR=1,TPR=1). Umbral alto: todos predichos -, (FPR=0,TPR=0). Eval√∫a discriminaci√≥n independiente del umbral."
                    },
                    {
                        acronym: "AUC",
                        name: "Area Under ROC Curve",
                        definition: "AUC=‚à´‚ÇÄ¬πTPR(FPR)dFPR‚àà[0,1]. Interpretaci√≥n: probabilidad que modelo rankee ejemplo positivo aleatorio m√°s alto que negativo aleatorio. AUC=0.5: aleatorio (diagonal). AUC=1.0: perfecto. T√≠picamente 0.5-1.0. AUC<0.5 indica predicciones invertidas."
                    }
                ]
                },
                {
                    subid: "1.3.3",
                    subtitle: "Bias Variance Trade-off",
                    description: "Equilibrio entre sesgo y varianza para entender el rendimiento y generalizaci√≥n del modelo.",
                    concepts: [
                    {
                        acronym: "Bias",
                        name: "Model Bias",
                        definition: "Diferencia entre predicci√≥n promedio del modelo y valor verdadero. Alto bias: modelo muy simple, no captura patrones (underfitting). Ejemplo: regresi√≥n lineal para datos no-lineales. S√≠ntomas: error alto en train Y test. Soluci√≥n: modelo m√°s complejo, m√°s features, menos regularizaci√≥n."
                    },
                    {
                        acronym: "Variance",
                        name: "Model Variance",
                        definition: "Cu√°nto cambiar√≠an predicciones si entrenamos con diferentes datasets. Alta variance: modelo muy sensible a datos espec√≠ficos (overfitting). Ejemplo: √°rbol muy profundo. S√≠ntomas: error bajo en train, alto en test. Soluci√≥n: m√°s datos, regularizaci√≥n, ensemble, arquitectura m√°s simple."
                    },
                    {
                        acronym: "Underfit",
                        name: "Underfitting",
                        definition: "Modelo muy simple para capturar patrones. Alto bias, bajo variance. Error alto en train Y test. Causas: (1) Modelo muy simple, (2) Features inadecuados, (3) Regularizaci√≥n excesiva. Soluciones: aumentar complejidad, a√±adir features, reducir regularizaci√≥n."
                    },
                    {
                        acronym: "Overfit",
                        name: "Overfitting",
                        definition: "Modelo memoriza training data en lugar de aprender patrones generales. Bajo bias, alta variance. Error muy bajo en train, alto en test (gap grande). Causas: (1) Modelo muy complejo, (2) Poco training data, (3) Ruido, (4) Entrenar demasiado. Soluciones: regularizaci√≥n, m√°s datos, dropout, early stopping, data augmentation."
                    },
                    {
                        acronym: "B-V Tradeoff",
                        name: "Bias-Variance Tradeoff",
                        definition: "Error total=Bias¬≤+Variance+Irreducible Error. Reducir bias t√≠picamente aumenta variance y viceversa. Sweet spot: minimizar suma de ambos. Estrategia: (1) Empezar simple (alto bias), (2) Incrementar complejidad hasta variance aceptable, (3) Regularizar. DL moderno: enfoque en baja bias, controlando variance con regularizaci√≥n y muchos datos."
                    },
                    {
                        acronym: "Train-Test Gap",
                        name: "Train-Test Gap",
                        definition: "Diferencia entre error de train y test. Gap peque√±o: generaliza bien (puede ser underfitting si ambos altos). Gap grande: overfitting claro. Objetivo: error bajo en AMBOS. Monitorear gap gu√≠a decisiones: si crece, a√±adir regularizaci√≥n; si ambos altos, aumentar capacidad."
                    }
                ]
                }
            ]
        }
    ]
};